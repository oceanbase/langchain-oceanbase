{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Hybrid Search\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search with OceanBase Vector Store\n",
    "\n",
    "This notebook demonstrates the hybrid search capabilities of the OceanBase vector store, including vector search, sparse vector search, and full-text search with intelligent result fusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To use hybrid search features, you'll need to deploy a standalone OceanBase server and install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --name=ob433 -e MODE=mini -e OB_SERVER_IP=127.0.0.1 -p 2881:2881 -d oceanbase/oceanbase-ce:4.3.5-lts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And install the `langchain-oceanbase` integration package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU \"langchain-oceanbase\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the connection to OceanBase and set the memory usage ratio for vector data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyobvector import ObVecClient\n",
    "\n",
    "tmp_client = ObVecClient()\n",
    "tmp_client.perform_raw_text_sql(\"ALTER SYSTEM ob_vector_memory_limit_percentage = 30\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Configure the embedding model and initialize the OceanBase vector store with hybrid search capabilities. Here we use `FakeEmbeddings` for demonstration purposes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_oceanbase.vectorstores import OceanbaseVectorStore\n",
    "\n",
    "# Connection configuration\n",
    "connection_args = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"port\": \"2881\", \n",
    "    \"user\": \"root@test\",\n",
    "    \"password\": \"\",\n",
    "    \"db_name\": \"test\",\n",
    "}\n",
    "\n",
    "# Initialize embeddings (using FakeEmbeddings for demo)\n",
    "embeddings = FakeEmbeddings(size=384)\n",
    "\n",
    "# Create vector store with hybrid search capabilities\n",
    "vector_store = OceanbaseVectorStore(\n",
    "    embedding_function=embeddings,\n",
    "    table_name=\"hybrid_search_demo\",\n",
    "    connection_args=connection_args,\n",
    "    vidx_metric_type=\"l2\",\n",
    "    include_sparse=True,      # Enable sparse vector search\n",
    "    include_fulltext=True,    # Enable full-text search\n",
    "    drop_old=True,\n",
    "    embedding_dim=384,\n",
    ")\n",
    "\n",
    "print(\"Hybrid search vector store initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search Features\n",
    "\n",
    "### Vector Search\n",
    "\n",
    "Vector search provides semantic similarity matching using embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some sample documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Machine learning is a subset of artificial intelligence\",\n",
    "        metadata={\"topic\": \"AI\", \"author\": \"John Doe\", \"year\": 2024}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Deep learning uses neural networks for pattern recognition\",\n",
    "        metadata={\"topic\": \"AI\", \"author\": \"Jane Smith\", \"year\": 2023}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Natural language processing enables computers to understand human language\",\n",
    "        metadata={\"topic\": \"NLP\", \"author\": \"Bob Wilson\", \"year\": 2024}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Computer vision allows machines to interpret visual information\",\n",
    "        metadata={\"topic\": \"CV\", \"author\": \"Alice Brown\", \"year\": 2023}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Add documents to vector store\n",
    "ids = vector_store.add_documents(documents)\n",
    "print(f\"Added {len(ids)} documents to the vector store\")\n",
    "\n",
    "# Perform basic vector search\n",
    "results = vector_store.similarity_search(\"artificial intelligence\", k=3)\n",
    "print(f\"\\nVector search results for 'artificial intelligence':\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Vector Search\n",
    "\n",
    "Sparse vector search is useful for keyword-based exact matching:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse embeddings for the documents\n",
    "# Each sparse vector represents keyword weights\n",
    "sparse_embeddings = [\n",
    "    {1: 0.8, 5: 0.6, 10: 0.4, 15: 0.2},  # machine learning AI\n",
    "    {2: 0.7, 6: 0.5, 11: 0.3, 16: 0.1},  # deep learning neural\n",
    "    {3: 0.9, 7: 0.4, 12: 0.6, 17: 0.3},  # natural language processing\n",
    "    {4: 0.6, 8: 0.8, 13: 0.2, 18: 0.5},  # computer vision\n",
    "]\n",
    "\n",
    "# Add documents with sparse embeddings\n",
    "sparse_ids = vector_store.add_sparse_documents(\n",
    "    documents=documents,\n",
    "    sparse_embeddings=sparse_embeddings,\n",
    ")\n",
    "print(f\"Added sparse embeddings for {len(sparse_ids)} documents\")\n",
    "\n",
    "# Perform sparse vector search\n",
    "sparse_query = {1: 0.8, 5: 0.6, 10: 0.4}  # Query for \"machine learning AI\"\n",
    "sparse_results = vector_store.similarity_search_with_sparse_vector(\n",
    "    sparse_query=sparse_query,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"\\nSparse vector search results:\")\n",
    "for i, doc in enumerate(sparse_results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-text Search\n",
    "\n",
    "Full-text search enables searching within document content:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full-text content for the documents\n",
    "fulltext_content = [\n",
    "    \"Machine learning algorithms enable computers to learn from data without explicit programming\",\n",
    "    \"Deep learning neural networks can process complex patterns in images and text\",\n",
    "    \"Natural language processing combines computational linguistics with machine learning\",\n",
    "    \"Computer vision systems can identify objects and scenes in digital images\",\n",
    "]\n",
    "\n",
    "# Add documents with full-text content\n",
    "fulltext_ids = vector_store.add_documents_with_fulltext(\n",
    "    documents=documents,\n",
    "    fulltext_content=fulltext_content,\n",
    ")\n",
    "print(f\"Added full-text content for {len(fulltext_ids)} documents\")\n",
    "\n",
    "# Perform full-text search\n",
    "fulltext_results = vector_store.similarity_search_with_fulltext(\n",
    "    query=\"artificial intelligence\",\n",
    "    fulltext_query=\"neural networks\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"\\nFull-text search results:\")\n",
    "for i, doc in enumerate(fulltext_results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Hybrid Search\n",
    "\n",
    "The most powerful feature is combining all three search modalities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced hybrid search combining all three modalities\n",
    "hybrid_results = vector_store.advanced_hybrid_search(\n",
    "    vector_query=\"AI technology\",           # Semantic search\n",
    "    sparse_query={1: 0.8, 5: 0.6},        # Keyword search\n",
    "    fulltext_query=\"machine learning\",     # Text search\n",
    "    k=4\n",
    ")\n",
    "\n",
    "print(f\"Advanced hybrid search results (default weights):\")\n",
    "for i, doc in enumerate(hybrid_results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n",
    "\n",
    "# Advanced hybrid search with custom weights\n",
    "custom_weights = {\n",
    "    'vector': 0.7,      # Emphasize semantic similarity\n",
    "    'sparse': 0.2,      # Reduce keyword matching\n",
    "    'fulltext': 0.1     # Reduce text search\n",
    "}\n",
    "\n",
    "weighted_results = vector_store.advanced_hybrid_search(\n",
    "    vector_query=\"AI technology\",\n",
    "    sparse_query={1: 0.8, 5: 0.6},\n",
    "    fulltext_query=\"machine learning\",\n",
    "    k=4,\n",
    "    modality_weights=custom_weights\n",
    ")\n",
    "\n",
    "print(f\"Advanced hybrid search results (custom weights):\")\n",
    "for i, doc in enumerate(weighted_results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Filtering\n",
    "\n",
    "You can also combine hybrid search with advanced filtering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced filtering with hybrid search\n",
    "filters = {\n",
    "    'fulltext': 'machine learning'\n",
    "}\n",
    "\n",
    "filtered_results = vector_store.similarity_search_with_advanced_filters(\n",
    "    query=\"artificial intelligence\",\n",
    "    filters=filters,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"Advanced filtering results:\")\n",
    "for i, doc in enumerate(filtered_results, 1):\n",
    "    print(f\"{i}. {doc.page_content[:50]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "### Multi-modal Search\n",
    "- **Vector Search**: Semantic similarity matching using embeddings\n",
    "- **Sparse Vector Search**: Keyword-based exact matching\n",
    "- **Full-text Search**: Content-based text search\n",
    "\n",
    "### Intelligent Result Fusion\n",
    "- Combines results from multiple search modalities\n",
    "- Uses weighted scoring system for optimal ranking\n",
    "- Normalizes scores across different modalities\n",
    "\n",
    "### Flexible Configuration\n",
    "- Enable/disable specific search modalities\n",
    "- **Configurable weights for different search types** (NEW!)\n",
    "- Support for various distance metrics\n",
    "- Custom weight validation and error handling\n",
    "\n",
    "### Performance Optimized\n",
    "- Leverages OceanBase's vector indexes\n",
    "- Parallel execution of multiple searches\n",
    "- Efficient result fusion algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The OceanBase Vector Store hybrid search provides:\n",
    "\n",
    "- **True multi-modal search** combining vector, sparse vector, and full-text search\n",
    "- **Intelligent result fusion** with **configurable weights** (NEW!)\n",
    "- **High performance** leveraging OceanBase's native capabilities\n",
    "- **Flexible configuration** for different use cases\n",
    "- **Backward compatibility** with existing vector search functionality\n",
    "- **Weight validation** ensuring proper configuration\n",
    "\n",
    "### Weight Configuration Examples\n",
    "\n",
    "```python\n",
    "# Default weights (automatic)\n",
    "results = vector_store.advanced_hybrid_search(\n",
    "    vector_query=\"AI technology\",\n",
    "    sparse_query={1: 0.8, 5: 0.6},\n",
    "    fulltext_query=\"machine learning\"\n",
    ")\n",
    "\n",
    "# Custom weights emphasizing semantic similarity\n",
    "semantic_weights = {'vector': 0.8, 'sparse': 0.1, 'fulltext': 0.1}\n",
    "results = vector_store.advanced_hybrid_search(\n",
    "    vector_query=\"AI technology\",\n",
    "    sparse_query={1: 0.8, 5: 0.6},\n",
    "    fulltext_query=\"machine learning\",\n",
    "    modality_weights=semantic_weights\n",
    ")\n",
    "\n",
    "# Custom weights emphasizing keyword matching\n",
    "keyword_weights = {'vector': 0.2, 'sparse': 0.7, 'fulltext': 0.1}\n",
    "results = vector_store.advanced_hybrid_search(\n",
    "    vector_query=\"AI technology\",\n",
    "    sparse_query={1: 0.8, 5: 0.6},\n",
    "    fulltext_query=\"machine learning\",\n",
    "    modality_weights=keyword_weights\n",
    ")\n",
    "```\n",
    "\n",
    "This makes it ideal for applications requiring both semantic understanding and precise keyword matching, such as academic paper search, product catalogs, and knowledge bases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
